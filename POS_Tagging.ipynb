{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    "- Understand how to retrieve Parts-of-Speech using Spacy\n",
    "- Understand how to use Named Entity Recognition with Spacy\n",
    "- Visualize POS and NER\n",
    "- Perform Sentence Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Basics\n",
    "The challenge of correctly identifying parts of speech is summed up nicely in the [spaCy docs](https://spacy.io/usage/linguistic-features):\n",
    "<div class=\"alert alert-info\" style=\"margin: 20px\">Processing raw text intelligently is difficult: most words are rare, and it's common for words that look completely different to mean almost the same thing. The same words in a different order can mean something completely different. Even splitting text into useful word-like units can be difficult in many languages. While it's possible to solve some problems starting from only the raw characters, it's usually better to use linguistic knowledge to add useful information. That's exactly what spaCy is designed to do: you put in raw text, and get back a Doc object, that comes with a variety of annotations.</div>\n",
    "In this section we'll take a closer look at coarse POS tags (noun, verb, adjective) and fine-grained tags (plural noun, past-tense verb, superlative adjective)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View token tags\n",
    "Recall that you can obtain a particular token by its index position.\n",
    "* To view the coarse POS tag use `token.pos_`\n",
    "* To view the fine-grained tag use `token.tag_`\n",
    "* To view the description of either type of tag use `spacy.explain(tag)`\n",
    "\n",
    "<div class=\"alert alert-success\">Note that `token.pos` and `token.tag` return integer hash values; by adding the underscores we get the text equivalent that lives in **doc.vocab**.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumped over a lazy dog's back.\n",
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "# Create a Spacy Doc object\n",
    "\n",
    "doc = nlp(u\"The quick brown fox jumped over a lazy dog's back.\")\n",
    "print(doc.text)\n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown fox\n",
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "# Create a Spacy Span object\n",
    "\n",
    "span = doc[2:4]\n",
    "print(span.text)\n",
    "print(type(span))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumped\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "# Create a Spacy token object\n",
    "\n",
    "toke = doc[4]\n",
    "print(toke.text)\n",
    "print(type(toke))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumped\n",
      "VERB\n",
      "VBD\n",
      "verb, past tense\n",
      "jump\n"
     ]
    }
   ],
   "source": [
    "# Print token tags\n",
    "\n",
    "print(toke.text)\n",
    "print(toke.pos_)\n",
    "print(toke.tag_)\n",
    "print(str(spacy.explain(toke.tag_)))\n",
    "print(toke.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The       DET       DT        determiner\n",
      "quick     ADJ       JJ        adjective\n",
      "brown     ADJ       JJ        adjective\n",
      "fox       NOUN      NN        noun, singular or mass\n",
      "jumped    VERB      VBD       verb, past tense\n",
      "over      ADP       IN        conjunction, subordinating or preposition\n",
      "a         DET       DT        determiner\n",
      "lazy      ADJ       JJ        adjective\n",
      "dog       NOUN      NN        noun, singular or mass\n",
      "'s        PART      POS       possessive ending\n",
      "back      NOUN      NN        noun, singular or mass\n",
      ".         PUNCT     .         punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "#Print tags for the complete doc object\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:{10}}{token.pos_:{10}}{token.tag_:{10}}{str(spacy.explain(token.tag_))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse-grained Part-of-speech Tags\n",
    "Every token is assigned a POS Tag from the following list:\n",
    "\n",
    "\n",
    "<table><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr>\n",
    "    \n",
    "<tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr>\n",
    "<tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>*'s, not,*</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr>\n",
    "<tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>*$, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù*</td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr>\n",
    "<tr><td>SPACE</td><td>space</td></tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Fine-grained POS Tag Examples\n",
    "These are some grammatical examples (shown in **bold**) of specific fine-grained tags. We've removed punctuation and rarely used tags:\n",
    "<table>\n",
    "<tr><th>POS</th><th>TAG</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
    "<tr><td>ADJ</td><td>AFX</td><td>affix</td><td>The Flintstones were a **pre**-historic family.</td></tr>\n",
    "<tr><td>ADJ</td><td>JJ</td><td>adjective</td><td>This is a **good** sentence.</td></tr>\n",
    "<tr><td>ADJ</td><td>JJR</td><td>adjective, comparative</td><td>This is a **better** sentence.</td></tr>\n",
    "<tr><td>ADJ</td><td>JJS</td><td>adjective, superlative</td><td>This is the **best** sentence.</td></tr>\n",
    "<tr><td>ADJ</td><td>PDT</td><td>predeterminer</td><td>Waking up is **half** the battle.</td></tr>\n",
    "<tr><td>ADJ</td><td>PRP\\$</td><td>pronoun, possessive</td><td>**His** arm hurts.</td></tr>\n",
    "<tr><td>ADJ</td><td>WDT</td><td>wh-determiner</td><td>It's blue, **which** is odd.</td></tr>\n",
    "<tr><td>ADJ</td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>We don't know **whose** it is.</td></tr>\n",
    "<tr><td>ADP</td><td>IN</td><td>conjunction, subordinating or preposition</td><td>It arrived **in** a box.</td></tr>\n",
    "<tr><td>ADV</td><td>EX</td><td>existential there</td><td>**There** is cake.</td></tr>\n",
    "<tr><td>ADV</td><td>RB</td><td>adverb</td><td>He ran **quickly**.</td></tr>\n",
    "<tr><td>ADV</td><td>RBR</td><td>adverb, comparative</td><td>He ran **quicker**.</td></tr>\n",
    "<tr><td>ADV</td><td>RBS</td><td>adverb, superlative</td><td>He ran **fastest**.</td></tr>\n",
    "<tr><td>ADV</td><td>WRB</td><td>wh-adverb</td><td>**When** was that?</td></tr>\n",
    "<tr><td>CONJ</td><td>CC</td><td>conjunction, coordinating</td><td>The balloon popped **and** everyone jumped.</td></tr>\n",
    "<tr><td>DET</td><td>DT</td><td>determiner</td><td>**This** is **a** sentence.</td></tr>\n",
    "<tr><td>INTJ</td><td>UH</td><td>interjection</td><td>**Um**, I don't know.</td></tr>\n",
    "<tr><td>NOUN</td><td>NN</td><td>noun, singular or mass</td><td>This is a **sentence**.</td></tr>\n",
    "<tr><td>NOUN</td><td>NNS</td><td>noun, plural</td><td>These are **words**.</td></tr>\n",
    "<tr><td>NOUN</td><td>WP</td><td>wh-pronoun, personal</td><td>**Who** was that?</td></tr>\n",
    "<tr><td>NUM</td><td>CD</td><td>cardinal number</td><td>I want **three** things.</td></tr>\n",
    "<tr><td>PART</td><td>POS</td><td>possessive ending</td><td>Fred**'s** name is short.</td></tr>\n",
    "<tr><td>PART</td><td>RP</td><td>adverb, particle</td><td>Put it **back**!</td></tr>\n",
    "<tr><td>PART</td><td>TO</td><td>infinitival to</td><td>I want **to** go.</td></tr>\n",
    "<tr><td>PRON</td><td>PRP</td><td>pronoun, personal</td><td>**I** want **you** to go.</td></tr>\n",
    "<tr><td>PROPN</td><td>NNP</td><td>noun, proper singular</td><td>**Kilroy** was here.</td></tr>\n",
    "<tr><td>PROPN</td><td>NNPS</td><td>noun, proper plural</td><td>The **Flintstones** were a pre-historic family.</td></tr>\n",
    "<tr><td>VERB</td><td>MD</td><td>verb, modal auxiliary</td><td>This **could** work.</td></tr>\n",
    "<tr><td>VERB</td><td>VB</td><td>verb, base form</td><td>I want to **go**.</td></tr>\n",
    "<tr><td>VERB</td><td>VBD</td><td>verb, past tense</td><td>This **was** a sentence.</td></tr>\n",
    "<tr><td>VERB</td><td>VBG</td><td>verb, gerund or present participle</td><td>I am **going**.</td></tr>\n",
    "<tr><td>VERB</td><td>VBN</td><td>verb, past participle</td><td>The treasure was **lost**.</td></tr>\n",
    "<tr><td>VERB</td><td>VBP</td><td>verb, non-3rd person singular present</td><td>I **want** to go.</td></tr>\n",
    "<tr><td>VERB</td><td>VBZ</td><td>verb, 3rd person singular present</td><td>He **wants** to go.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with POS Tags\n",
    "In the English language, the same string of characters can have different meanings, even within the same sentence. For this reason, morphology is important. **spaCy** uses machine learning algorithms to best predict the use of a token in a sentence. Is *\"I read books on NLP\"* present or past tense? Is *wind* a verb or a noun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"You read books on NLP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read\n"
     ]
    }
   ],
   "source": [
    "token = doc1[1]\n",
    "print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB       VBP        verb, non-3rd person singular present\n"
     ]
    }
   ],
   "source": [
    "print(f'{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"i read a book on NLP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read\n"
     ]
    }
   ],
   "source": [
    "token = doc2[1]\n",
    "print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB       VBD        verb, past tense\n"
     ]
    }
   ],
   "source": [
    "print(f'{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumped over a lazy dog's back.\n"
     ]
    }
   ],
   "source": [
    "# Counting the POS tags\n",
    "\n",
    "doc = nlp(u\"The quick brown fox jumped over a lazy dog's back.\")\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{90: 2, 84: 3, 92: 3, 100: 1, 85: 1, 94: 1, 97: 1}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_counts = doc.count_by(spacy.attrs.POS)\n",
    "POS_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   84. ADJ   3\n",
      "   85. ADP   1\n",
      "   90. DET   2\n",
      "   92. NOUN  3\n",
      "   94. PART  1\n",
      "   97. PUNCT 1\n",
      "  100. VERB  1\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f\"{k:{5}}. {doc.vocab[k].text:{5}} {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  74. POS   1\n",
      " 1292078113972184607. IN    1\n",
      "10554686591937588953. JJ    3\n",
      "12646065887601541794. .     1\n",
      "15267657372422890137. DT    2\n",
      "15308085513773655218. NN    3\n",
      "17109001835818727656. VBD   1\n"
     ]
    }
   ],
   "source": [
    "# Counting the TAGs\n",
    "\n",
    "TAG_counts = doc.count_by(spacy.attrs.TAG)\n",
    "\n",
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f\"{k:{20}}. {doc.vocab[k].text:{5}} {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 402. amod  3\n",
      "                 415. det   2\n",
      "                 429. nsubj 1\n",
      "                 439. pobj  1\n",
      "                 440. poss  1\n",
      "                 443. prep  1\n",
      "                 445. punct 1\n",
      " 8110129090154140942. case  1\n",
      " 8206900633647566924. ROOT  1\n"
     ]
    }
   ],
   "source": [
    "# Counting the DEPs\n",
    "\n",
    "DEP_counts = doc.count_by(spacy.attrs.DEP)\n",
    "\n",
    "for k,v in sorted(DEP_counts.items()):\n",
    "    print(f\"{k:{20}}. {doc.vocab[k].text:{5}} {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
