{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Often when searching text for a certain keyword, it helps if the search returns variations of the word. For instance, searching for \"boat\" might also return \"boats\" and \"boating\". Here, \"boat\" would be the **stem** for [boat, boater, boating, boats].\n",
    "\n",
    "Stemming is a somewhat crude method for cataloging related words; it essentially chops off letters from the end until the stem is reached. This works fairly well in most cases, but unfortunately English has many exceptions where a more sophisticated process is required. In fact, spaCy doesn't include a stemmer, opting instead to rely entirely on lemmatization. For those interested, there's some background on this decision [here](https://github.com/explosion/spaCy/issues/327). We discuss the virtues of *lemmatization* in the next section.\n",
    "\n",
    "Instead, we'll use another popular NLP tool called **nltk**, which stands for *Natural Language Toolkit*. For more information on nltk visit https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porter Stemmer\n",
    "\n",
    "One of the most common - and effective - stemming tools is [*Porter's Algorithm*](https://tartarus.org/martin/PorterStemmer/) developed by Martin Porter in [1980](https://tartarus.org/martin/PorterStemmer/def.txt). The algorithm employs five phases of word reduction, each with its own set of mapping rules.\n",
    "\n",
    "- In the first phase, simple suffix mapping rules are defined.\n",
    "- More sophisticated phases consider the length/complexity of the word before applying a rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Porter Stemmer\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object\n",
    "\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','ran','runs','easily','fairly','fairness','functional','university']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run---->run\n",
      "runner---->runner\n",
      "ran---->ran\n",
      "runs---->run\n",
      "easily---->easili\n",
      "fairly---->fairli\n",
      "fairness---->fair\n",
      "functional---->function\n",
      "university---->univers\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '---->' + p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowball Stemmer\n",
    "\n",
    "It is a stemming language developed by Martin Porter. The algorithm used here is more accurately called the \"English Stemmer\" or \"Porter2 Stemmer\". It offers a slight improvement over the original Porter Stemmer, both in logic and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Snowball Stemmer\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snow_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run---->run\n",
      "runner---->runner\n",
      "ran---->ran\n",
      "runs---->run\n",
      "easily---->easili\n",
      "fairly---->fair\n",
      "fairness---->fair\n",
      "functional---->function\n",
      "university---->univers\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '---->' + snow_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['generous','generation','generously','generate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous---->generous\n",
      "generation---->generat\n",
      "generously---->generous\n",
      "generate---->generat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '---->' + snow_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We --> we\n",
      "are --> are\n",
      "meeting --> meet\n",
      "him --> him\n",
      "tomorrow --> tomorrow\n",
      "at --> at\n",
      "the --> the\n",
      "meeting --> meet\n"
     ]
    }
   ],
   "source": [
    "phrase = 'We are meeting him tomorrow at the meeting'\n",
    "for word in phrase.split():\n",
    "    print(word+' --> '+snow_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancaster Stemmer\n",
    "\n",
    "The LancasterStemmer (Paice-Husk stemmer) is an iterative algorithm with rules saved externally. One table containing about 120 rules indexed by the last letter of a suffix. On each iteration, it tries to find an applicable rule by the last character of the word. Each rule specifies either a deletion or replacement of an ending. If there is no such rule, it terminates. It also terminates if a word starts with a vowel and there are only two letters left or if a word starts with a consonant and there are only three characters left. Otherwise, the rule is applied, and the process repeats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LancasterStemmer is simple, but heavy stemming due to iterations and over-stemming may occur. Over-stemming causes the stems to be not linguistic, or they may have no meaning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "l_stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run---->run\n",
      "runner---->run\n",
      "ran---->ran\n",
      "runs---->run\n",
      "easily---->easy\n",
      "fairly---->fair\n",
      "fairness---->fair\n",
      "functional---->funct\n",
      "university---->univers\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '---->' + l_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A list of words to be stemmed\n",
    "\n",
    "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                 PorterStemmer        SnowballStemmer      LancasterStemmer    \n",
      "friend               friend               friend               friend              \n",
      "friendship           friendship           friendship           friend              \n",
      "friends              friend               friend               friend              \n",
      "friendships          friendship           friendship           friend              \n",
      "stabil               stabil               stabil               stabl               \n",
      "destabilize          destabil             destabil             dest                \n",
      "misunderstanding     misunderstand        misunderstand        misunderstand       \n",
      "railroad             railroad             railroad             railroad            \n",
      "moonlight            moonlight            moonlight            moonlight           \n",
      "football             footbal              footbal              footbal             \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Word':{20}} {'PorterStemmer':{20}} {'SnowballStemmer':{20}} {'LancasterStemmer':{20}}\")\n",
    "for word in word_list:\n",
    "    print(f'{word:{20}} {p_stemmer.stem(word):{20}} {snow_stemmer.stem(word):{20}} {l_stemmer.stem(word):{20}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
